[{"authors":null,"categories":null,"content":"\u0026hellip;\n","date":1530136800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530136800,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://theoceancode.netlify.com/privacy/","publishdate":"2018-06-28T00:00:00+02:00","relpermalink":"/privacy/","section":"","summary":"\u0026hellip;","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["RW Schlegel","ECJ Oliver","S Perkins-Kirkpatrick","A Kruger","AJ Smit"],"categories":null,"content":"","date":1508191200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508191200,"objectID":"0b102118b91144a4196a666ef4f2aefc","permalink":"https://theoceancode.netlify.com/publication/predominant/","publishdate":"2017-10-17T00:00:00+02:00","relpermalink":"/publication/predominant/","section":"publication","summary":"As the mean temperatures of the worlds oceans increase, it is predicted that marine heatwaves (MHWs) will occur more frequently and with increased severity. However, it has been shown that variables other than increases in sea water temperature have been responsible for MHWs. To better understand these mechanisms driving MHWs we have utilized atmospheric (ERA-Interim) and oceanic (OISST, AVISO) data to examine the patterns around southern Africa during coastal (","tags":["R","coastal","atmosphere","ocean"],"title":"Predominant Atmospheric and Oceanic Patterns during Coastal Marine Heatwaves","type":"publication"},{"authors":null,"categories":["R"],"content":"Objective With more and more scientists moving to open source software (i.e. R or Python) to perform their numerical analyses the opportunities for collaboration increase and we may all benefit from this enhanced productivity. At the risk of sounding sycophantic, the future of scientific research truly is in multi-disciplinary work. What then could be inhibiting this slow march towards progress? We tend to like to stick to what is comfortable. Oceanographers in South Africa have been using MATLAB and ODV (Ocean Data View) since about the time that Jesus was lacing up his sandals for his first trip to Palestine. There has been much debate on the future of MATLAB in science, so I won’t get into that here, but I will say that the package oce contains much of the code that one would need for oceanographic work in R, and the package angstroms helps one to work with ROMS (Regional Ocean Modeling System) output. The software that has however largely gone under the radar in these software debates has been ODV. Probably because it is free (after registration) it’s fate has not been sealed by university departments looking to cut costs. The issue with ODV however is the same with all Microsoft products; the sin of having a “pointy clicky” user interface. One cannot perform truly reproducible research with a menu driven user interface. The steps must be written out in code. And so here I will lay out those necessary steps to create an interpolated CTD time series of temperature values that looks as close to the default output of ODV as possible.\nFigure 1: The default output of ODV when plotting temperature by depth through time at one location.\n  Colour palette Perhaps the most striking thing about the figures that ODV creates is it’s colour palette. A large criticism of this colour palette is that the range of colours used are not equally weighted visually, with the bright reds drawing ones eye more than the muted blues. This issue can be made up for using the viridis package, but for now we will stick to a ODV-like colour palette as that is part of our current objective. To create a colour palette that appears close to the ODV standard I used GIMP to extract the hexadecimal colour values from the colour bar in Figure 1.\n# Load libraries library(tidyverse) library(lubridate) library(reshape2) library(MBA) library(mgcv) # Load and screen data # For ease I am only using monthly means # and depth values rounded to 0.1 metres ctd \u0026lt;- read_csv(\u0026quot;../../static/data/ctd.csv\u0026quot;) %\u0026gt;% mutate(depth = -depth) %\u0026gt;% # Correct for plotting filter(site == 1) %\u0026gt;% select(date, depth, temperature) %\u0026gt;% rename(temp = temperature) #%\u0026gt;% ### Uncomment out the following lines to reduce the data resolution # mutate(date = round_date(date, unit = \u0026quot;month\u0026quot;)) %\u0026gt;% # mutate(depth = round(depth, 1)) %\u0026gt;% # group_by(date, depth) %\u0026gt;% # summarise(temp = round(mean(temp, na.rm = TRUE),1)) ### # Manually extracted hexidecimal ODV colour palette ODV_colours \u0026lt;- c(\u0026quot;#feb483\u0026quot;, \u0026quot;#d31f2a\u0026quot;, \u0026quot;#ffc000\u0026quot;, \u0026quot;#27ab19\u0026quot;, \u0026quot;#0db5e6\u0026quot;, \u0026quot;#7139fe\u0026quot;, \u0026quot;#d16cfa\u0026quot;) # Create quick scatterplot ggplot(data = ctd, aes(x = date, y = depth)) + geom_point(aes(colour = temp)) + scale_colour_gradientn(colours = rev(ODV_colours)) + labs(y = \u0026quot;depth (m)\u0026quot;, x = NULL, colour = \u0026quot;temp. (°C)\u0026quot;) Figure 2: A non-interpolated scatterplot of our temperature (°C) data shown as a function of depth (m) over time.\n Interpolating Figure 2 is a far cry from the final product we want, but it is a step in the right direction. One of the things that sets ODV apart from other visualisation software is that it very nicely interpolates the data you give it. While this looks nice, there is some criticism that may be leveled against doing so. That being said, what we want is a pretty visualisation of our data. We are not going to be using these data for any numerical analyses so the main priority is that the output allows us to better visually interpret the data. The package MBA already has the necessary functionality to do this, and it works with ggplot2, so we will be using this to get our figure. The interpolation method used by mba.surf() is multilevel B-splines.\nIn order to do so we will need to dcast() our data into a wide format so that it simulates a surface layer. spread() from the tidyr package doesn’t quite do what we need as we want a proper surface map, which is outside of the current ideas on the structuring of tidy data. Therefore, after casting our data wide we will use melt(), rather than gather(), to get the data back into long format so that it works with ggplot2.\nIt is important to note with the use of mba.surf() that it transposes the values while it is creating the calculations and so creating an uneven grid does not work well. Using the code written below one will always need to give the same specifications for pixel count on the x and y axes.\n# The date column must then be converted to numeric values ctd$date \u0026lt;- decimal_date(ctd$date) # Now we may interpolate the data ctd_mba \u0026lt;- mba.surf(ctd, no.X = 300, no.Y = 300, extend = T) dimnames(ctd_mba$xyz.est$z) \u0026lt;- list(ctd_mba$xyz.est$x, ctd_mba$xyz.est$y) ctd_mba \u0026lt;- melt(ctd_mba$xyz.est$z, varnames = c(\u0026#39;date\u0026#39;, \u0026#39;depth\u0026#39;), value.name = \u0026#39;temp\u0026#39;) %\u0026gt;% filter(depth \u0026lt; 0) %\u0026gt;% mutate(temp = round(temp, 1)) # Finally we create our gridded result ggplot(data = ctd_mba, aes(x = date, y = depth)) + geom_raster(aes(fill = temp)) + scale_fill_gradientn(colours = rev(ODV_colours)) + geom_contour(aes(z = temp), binwidth = 2, colour = \u0026quot;black\u0026quot;, alpha = 0.2) + geom_contour(aes(z = temp), breaks = 20, colour = \u0026quot;black\u0026quot;) + ### Activate to see which pixels are real and not interpolated # geom_point(data = ctd, aes(x = date, y = depth), # colour = \u0026#39;black\u0026#39;, size = 0.2, alpha = 0.4, shape = 8) + ### labs(y = \u0026quot;depth (m)\u0026quot;, x = NULL, fill = \u0026quot;temp. (°C)\u0026quot;) + coord_cartesian(expand = 0) Figure 3: The same temperature (°C) profiles seen in Figure 2 with the missing values filled in with multilevel B-splines. Note the artefact created in the bottom right corner. The 20°C contour line is highlighted in black.\nAt first glance this now appears to be a very good approximation of the output from ODV. An astute eye will have noticed that the temperatures along the bottom right corner of this figure are not interpolating in a way that appears possible. It is very unlikely that there would be a deep mixed layer underneath the thermoclines detected during 2015. The reason the splines create this artefact is that they are based on a convex hull around the real data points and so the interpolating algorithm wants to perform a regression towards a mean value away from the central point of where the spline is being calculated from. Because the thermoclines detected are interspersed between times where the entire water column consists of a mixed layer mba.surf() is filling in the areas without data as though they are a fully mixed surface layer.\n Bounding boxes There are many ways to deal with this problem with four possible fixes coming to mind quickly. The first is to set extend = F within mba.surf(). This tells the algorithm not to fill up every part of the plotting area and will alleviate some of the inaccurate interpolation that occurs but will not eliminate it. The second fix, which would prevent all inaccurate interpolation would be to limit the depth of all of the temperature profiles to be the same as the shallowest sampled profile. This is not an ideal fix because we would then lose quite a bit of information from the deeper sampling that occurred from 2013 to 2014. The third fix is to create a bounding box and screen out all of the interpolated data outside of it. A fourth option is to use soap-film smoothing over some other interpolation method, such as a normal GAM, concurrently with a bounding box. This is normally a good choice but does not work well with these data so I have gone with option three.\n# Create a bounding box # We want to slightly extend the edges so as to use all of our data left \u0026lt;- ctd[ctd$date == min(ctd$date),] %\u0026gt;% select(-temp) %\u0026gt;% ungroup() %\u0026gt;% mutate(date = date-0.01) bottom \u0026lt;- ctd %\u0026gt;% group_by(date) %\u0026gt;% summarise(depth = min(depth)) %\u0026gt;% mutate(depth = depth-0.01) right \u0026lt;- ctd[ctd$date == max(ctd$date),] %\u0026gt;% select(-temp) %\u0026gt;% ungroup() %\u0026gt;% mutate(date = date+0.01) top \u0026lt;- ctd %\u0026gt;% group_by(date) %\u0026gt;% summarise(depth = max(depth)) %\u0026gt;% mutate(depth = depth+0.01) bounding_box \u0026lt;- rbind(data.frame(left[order(nrow(left):1),]), data.frame(bottom), data.frame(right), data.frame(top[order(nrow(top):1),])) # Now that we have a bounding box we need to # screen out the pixels created outside of it bounding_box_list \u0026lt;- list(bounding_box) names(bounding_box_list[[1]]) \u0026lt;- c(\u0026quot;v\u0026quot;,\u0026quot;w\u0026quot;) v \u0026lt;- ctd_mba$date w \u0026lt;- ctd_mba$depth ctd_mba_bound \u0026lt;- ctd_mba[inSide(bounding_box_list, v, w),] # Correct date values back to date format # Not used as it introduces blank space into the figure # ctd_mba_bound$date \u0026lt;- as.Date(format(date_decimal(ctd_mba_bound$date), \u0026quot;%Y-%m-%d\u0026quot;)) # The screened data ggplot(data = ctd_mba_bound, aes(x = date, y = depth)) + geom_raster(aes(fill = temp)) + scale_fill_gradientn(colours = rev(ODV_colours)) + geom_contour(aes(z = temp), binwidth = 2, colour = \u0026quot;black\u0026quot;, alpha = 0.2) + geom_contour(aes(z = temp), breaks = 20, colour = \u0026quot;black\u0026quot;) + labs(y = \u0026quot;depth (m)\u0026quot;, x = NULL, fill = \u0026quot;temp. (°C)\u0026quot;) + coord_cartesian(expand = 0) Figure 4: The same temperature (°C) profiles seen in Figure 3 with a bounding box used to screen out data interpolated outside of the range of the recordings.\n Summary In this short tutorial we have seen how to create an interpolated temperature depth profile over time after a fashion very similar to the default output from ODV. We have also seen how to either fill the entire plotting area with interpolated data (Figure 3), or quickly generate a bounding box in order to remove any potential interpolation artefacts (Figure 4). I think this is a relatively straight forward work flow and would work with any tidy dataset. It is worth noting that this is not constrained to depth profiles, but would work just as well with map data. One would only need to change the date and depth variables to lon and lat.\nR is an amazingly flexible language with an incredible amount of support and I’ve yet to see it not be able to emulate, or improve upon, an analysis or graphical output from any other software.\n ","date":1498435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498435200,"objectID":"0a1a1627413c7c8561ce3e3ac3e4f547","permalink":"https://theoceancode.netlify.com/post/odv_figures/","publishdate":"2017-06-26T00:00:00Z","relpermalink":"/post/odv_figures/","section":"post","summary":"Objective With more and more scientists moving to open source software (i.e. R or Python) to perform their numerical analyses the opportunities for collaboration increase and we may all benefit from this enhanced productivity. At the risk of sounding sycophantic, the future of scientific research truly is in multi-disciplinary work. What then could be inhibiting this slow march towards progress? We tend to like to stick to what is comfortable. Oceanographers in South Africa have been using MATLAB and ODV (Ocean Data View) since about the time that Jesus was lacing up his sandals for his first trip to Palestine.","tags":["ODV","visuals","interpolation"],"title":"ODV figures in R","type":"post"},{"authors":["RW Schlegel","ECJ Oliver","T Wernberg","AJ Smit"],"categories":null,"content":"","date":1483999200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483999200,"objectID":"23ea356d126b6305a8c493cb8e58c32a","permalink":"https://theoceancode.netlify.com/publication/cooccurrence/","publishdate":"2017-01-10T00:00:00+02:00","relpermalink":"/publication/cooccurrence/","section":"publication","summary":"A changing global climate places shallow water ecosystems at more risk than those in the open ocean as their temperatures may change more rapidly and dramatically. To this end, it is necessary to identify the occurrence of extreme ocean temperature events – marine heatwaves (MHWs) and marine cold-spells (MCSs) – in the nearshore (","tags":["R","coastal"],"title":"Nearshore and offshore co-occurrence of marine heatwaves and cold-spells","type":"publication"},{"authors":null,"categories":null,"content":"Embed your slides or video here using shortcodes. Further details can easily be added using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483221600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483221600,"objectID":"cd6d9d084287506b4668ad90c6aff50a","permalink":"https://theoceancode.netlify.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00+02:00","relpermalink":"/talk/example-talk/","section":"talk","summary":"Embed your slides or video here using shortcodes. Further details can easily be added using Markdown and $\\rm \\LaTeX$ math code.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["RW Schlegel","AJ Smit"],"categories":null,"content":"","date":1481752800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481752800,"objectID":"7ada37b9b35f6bf1c621e5e5947cc974","permalink":"https://theoceancode.netlify.com/publication/trend-analysis/","publishdate":"2016-12-15T00:00:00+02:00","relpermalink":"/publication/trend-analysis/","section":"publication","summary":"In South Africa, 129 in situ temperature time series of up to 43 years are used for investigations of the thermal characteristics of coastal seawater. They are collected with handheld thermometers or underwater temperature recorders (UTRs) and are recorded at precisions from 0.5° to 0.001°C. Using the natural range of seasonal signals and variability for 84 of these time series, their length, decadal trend, and data precision were systematically varied before fitting generalized least squares (GLS) models to study the effect these variables have on trend detection. The variables that contributed most to accurate trend detection, in decreasing order, were time series length, decadal trend, variance, percentage of missing data (% NA), and measurement precision. Time series greater than 30 years in length are preferred and although larger decadal trends are modeled more accurately, modeled significance (p value) is largely affected by the variance present. The risk of committing both type-1 and type-2 errors increases when ≥5% NA is present. There is no appreciable effect on model accuracy between measurement precision of 0.1°–0.001°C. Measurement precisions of 0.5°C require longer time series to give equally accurate model results. The implication is that the thermometer time series in this dataset, and others around the world, must be at least two years longer than their UTR counterparts to be useful for decadal-scale climate change studies. Furthermore, adding older lower-precision UTR data to newer higher-precision UTR data within the same time series will increase their usefulness for this purpose.","tags":["time series analysis","R"],"title":"Climate Change in Coastal Waters: Time Series Properties Affecting Trend Estimation","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461708000,"objectID":"80be3c9fcc86014efab0cec0f14957f6","permalink":"https://theoceancode.netlify.com/project/deep-learning/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/deep-learning/","section":"project","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit.","tags":["Deep Learning"],"title":"Deep Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461708000,"objectID":"553a94c5dfd3b8b099d8a12b2d248093","permalink":"https://theoceancode.netlify.com/project/example-external-project/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/example-external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"}]